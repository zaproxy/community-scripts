---
# A simple plan that performs a baseline scan against example.com
# It uses both of the spiders and just passive scanning.
# The 2 spider tests will fail as they do not find at least 100 URLs, 
# but they do not fail the whole plan as they just report at INFO level.
env:
  contexts:
  - name: "Example"
    urls:
    - "https://www.example.com/"
    includePaths: []
    excludePaths: []
    authentication:
      parameters: {}
      verification:
        method: "response"
        pollFrequency: 60
        pollUnits: "requests"
    sessionManagement:
      method: "cookie"
      parameters: {}
    technology:
      exclude: []
  parameters:
    failOnError: true
    failOnWarning: false
    progressToStdout: true
  vars: {}
jobs:
- parameters:
    scanOnlyInScope: true
    enableTags: false
  rules: []
  name: "passiveScan-config"
  type: "passiveScan-config"
- parameters: {}
  name: "spider"
  type: "spider"
  tests:
  - onFail: "INFO"
    statistic: "automation.spider.urls.added"
    site: ""
    operator: ">="
    value: 100
    type: "stats"
    name: "At least 100 URLs found"
- parameters:
    maxDuration: 60
    maxCrawlDepth: 10
    numberOfBrowsers: 1
  name: "spiderAjax"
  type: "spiderAjax"
  tests:
  - onFail: "INFO"
    statistic: "spiderAjax.urls.added"
    site: ""
    operator: ">="
    value: 100
    type: "stats"
    name: "At least 100 URLs found"
- parameters: {}
  name: "passiveScan-wait"
  type: "passiveScan-wait"
- parameters:
    template: "risk-confidence-html"
    reportTitle: "ZAP Scanning Report"
    reportDescription: ""
  name: "report"
  type: "report"

